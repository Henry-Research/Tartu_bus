{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bc7aa00-71ca-4791-b6d6-c1f82c8d0915",
   "metadata": {},
   "source": [
    "# Preparing data frames for machine learning methods\n",
    "\n",
    "This iterates through each data frame made in the previous pipe aned performs:\n",
    "\n",
    "a) KNN to fill in missing \"Number of ticket_validations\" \n",
    "\n",
    "b) Converts the niehborhood classification with one hot encoding\n",
    "\n",
    "c) identifies outlier unvalidated ticket counts and shrinks it relative to how much of an outlier it is, and the degree of support it has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6ad06de-7a5e-4b05-813e-5bf5508af3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import glob\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad5a020-9df1-4005-95c4-9459dad70ff7",
   "metadata": {},
   "source": [
    "### Inputing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c14fa239-98fc-4d19-9082-2e70404e7229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING - This imputation is likely incorrect. It would be wise to invesitgate WHY the value is NAN to begin with \n",
    "# it could be because there simlpy was not ticket validations for that time!!!\n",
    "# However, KNN should still provide a very low number if that is the case \n",
    "# However, it is something to be further inverstigated in the future\n",
    "\n",
    "def knn_fill_validation(df, k=10):\n",
    "    enc = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "    enc.fit(df[[\"NIMI\"]])\n",
    "\n",
    "    df_sub = df.copy()\n",
    "\n",
    "    # One-hot encode NIMI with global encoder\n",
    "    nimi_encoded = enc.transform(df_sub[[\"NIMI\"]])\n",
    "    nimi_cols = enc.get_feature_names_out([\"NIMI\"])\n",
    "    nimi_df = pd.DataFrame(nimi_encoded, columns=nimi_cols, index=df_sub.index)\n",
    "\n",
    "    # Build numeric matrix\n",
    "    matrix = pd.concat([\n",
    "        nimi_df,\n",
    "        df_sub[[\"Pre_2019\", \"density\", \"Rel_Visiting_score\", \"Validation_Count_mean\"]]\n",
    "    ], axis=1)\n",
    "\n",
    "    # Run imputer\n",
    "    imputer = KNNImputer(n_neighbors=k)\n",
    "    imputed = imputer.fit_transform(matrix)\n",
    "\n",
    "    # Put imputed values back\n",
    "    df_sub[\"Validation_Count_mean\"] = imputed[:, -1]\n",
    "\n",
    "    return df_sub\n",
    "    \n",
    "\n",
    "def Encoding_variables(df):\n",
    "    # extracting out time features \n",
    "    Final = df.drop(columns = \"Stop_ID\")\n",
    "    Final[\"Time_min\"] = (Final[\"Binned_time\"].dt.hour)*60\n",
    "    \n",
    "    Final[\"time_sin\"] = np.sin(2*np.pi*Final[\"Time_min\"]/1440)\n",
    "    Final[\"time_cos\"] = np.cos(2*np.pi*Final[\"Time_min\"]/1440)\n",
    "    \n",
    "    Final.drop(columns = [\"Time_min\"], inplace = True)\n",
    "\n",
    "\n",
    "    # one hot encoding day, inlcuding day of the week (if it exists)    \n",
    "\n",
    "    # Drop Binned_day if it only contains 0 \n",
    "    if len(df[\"Binned_day\"].unique() > 1): \n",
    "        Final = pd.get_dummies(Final, columns = [\"NIMI\", \"Binned_day\"])\n",
    "\n",
    "    else:\n",
    "        Final = pd.get_dummies(Final, columns = [\"NIMI\"])\n",
    "        Final.drop(columns = [\"Binned_day\"], inplace = True)\n",
    "        \n",
    "\n",
    "    Final.drop(columns = [\"Binned_time\"], inplace = True)\n",
    "    return Final\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70572484-75d2-40ed-bf5e-ef462870bd2d",
   "metadata": {},
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18a21046-6c17-48c1-81ec-54fac7b374c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encoding_variables(df):\n",
    "    # extracting out time features \n",
    "    Final = df.drop(columns = \"Stop_ID\")\n",
    "    Final[\"Time_min\"] = (Final[\"Binned_time\"].dt.hour)*60\n",
    "    \n",
    "    Final[\"time_sin\"] = np.sin(2*np.pi*Final[\"Time_min\"]/1440)\n",
    "    Final[\"time_cos\"] = np.cos(2*np.pi*Final[\"Time_min\"]/1440)\n",
    "    \n",
    "    Final.drop(columns = [\"Time_min\"], inplace = True)\n",
    "\n",
    "\n",
    "    # one hot encoding day, inlcuding day of the week (if it exists)    \n",
    "\n",
    "    # Drop Binned_day if it only contains 0 \n",
    "    if len(df[\"Binned_day\"].unique() > 1): \n",
    "        Final = pd.get_dummies(Final, columns = [\"NIMI\", \"Binned_day\"])\n",
    "\n",
    "    else:\n",
    "        Final = pd.get_dummies(Final, columns = [\"NIMI\"])\n",
    "        Final.drop(columns = [\"Binned_day\"], inplace = True)\n",
    "        \n",
    "\n",
    "    Final.drop(columns = [\"Binned_time\"], inplace = True)\n",
    "    return Final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16af90c7-f4d1-466b-a6aa-6d8b8953c455",
   "metadata": {},
   "source": [
    "### Outlier shrinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e272c29-3816-42c1-aebb-5be9a265b203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Outlier_shrinking(df, col=\"Unvalidated_mean\", support_col=\"n_rows\"):\n",
    "    min_support = 3\n",
    "    threshold = df[\"Unvalidated_mean\"].quantile(0.95)\n",
    "\n",
    "    # Calculate shrinkage factor\n",
    "    def shrink(row):\n",
    "        if row[col] > threshold and row[support_col] < min_support:\n",
    "            # Proportional shrinkage: the smaller the support, the more we shrink\n",
    "            support_factor = row[support_col] / min_support  # 0-1\n",
    "            extreme_factor = threshold / row[col]           # 0-1\n",
    "            shrink_factor = support_factor * extreme_factor\n",
    "            return row[col] * shrink_factor\n",
    "        else:\n",
    "            return row[col]\n",
    "    \n",
    "    df[col] = df.apply(shrink, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bc7deea-ecb8-40f1-82f1-c9a3240f00c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combo_120min_Collapseall\n",
      "Combo_120min_Dayofweek\n",
      "Combo_120min_Weekendsplit\n",
      "Combo_180min_Collapseall\n",
      "Combo_180min_Dayofweek\n",
      "Combo_180min_Weekendsplit\n",
      "Combo_30min_Collapseall\n",
      "Combo_30min_Dayofweek\n",
      "Combo_30min_Weekendsplit\n",
      "Combo_360min_Collapseall\n",
      "Combo_360min_Dayofweek\n",
      "Combo_360min_Weekendsplit\n",
      "Combo_60min_Collapseall\n",
      "Combo_60min_Dayofweek\n",
      "Combo_60min_Weekendsplit\n",
      "Combo_720min_Collapseall\n",
      "Combo_720min_Dayofweek\n",
      "Combo_720min_Weekendsplit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Performance = []\n",
    "\n",
    "files = glob.glob(\"c:/users/henry chapman/Documents/Coding/Data_science/Project_final/Output/2_Granularity_tuning/Pipe1/*.csv\")\n",
    "output_folder = \"C:/users/henry chapman/Documents/Coding/Data_science/Project_final/Output/2_Granularity_tuning/Pipe2\"\n",
    "for file in files:\n",
    "    Combo = os.path.basename(file).split(\".\")[0]\n",
    "    print(Combo)\n",
    "    df = pd.read_csv(file, parse_dates = [\"Binned_time\"])\n",
    "    Imputed_missing = knn_fill_validation(df)\n",
    "    # Drop any remaining NA values \n",
    "    Imputed_missing.dropna(inplace = True)\n",
    "\n",
    "    # Encode variables \n",
    "    Encoded = Encoding_variables(Imputed_missing)\n",
    "\n",
    "    # Shrinking outliers \n",
    "    Shrunk = Outlier_shrinking(Encoded)\n",
    "\n",
    "    # export df \n",
    "    Name = f\"{Combo}_Final.csv\"\n",
    "    Shrunk.to_csv(f\"{output_folder}/{Name}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e8f34e-4ecc-4113-a12e-67424a7445ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb974ca6-e79a-4d1d-86db-f600ce1c3b29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
